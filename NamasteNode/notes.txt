********************************** Class 3 *************************************

================================== Class 3 =====================================


    1. node REPL - READ, EVALUATE, PRINT, LOOP 
    2. we can see that in terminal like cmd it is very similar to console in browsers but the differnce is instead of Node JS we have browser which is also running 
         V8 engine behind the scenes.
    3. Node JS is JS runtime environment.
    4. Inside Node JS we have V8 JS engine and some super powers and whenever we wrote any piece of JS code, Node JS gave/passed that code to V8 engine and then V8 engine 
         actually executed that code (as V8 engine written in C++ so it converts that code into machine level code so the computer can understand it).

-----------first code of node js------------ 
    5. we can just create a file with the name let say app.js write the code and run it by the command node (file name) in the terminal.
    6. in browser, window is the global object and this also points to the global object and it is given to us by browsers and over here in Node JS we have the global object
         and it is known as global.
    7. setTimeout, setInterval, setImmediate all are given to us by the global object.
    8. so global is not a part of V8 engine as global is outside and it is one of the super powers given by Node JS.
    9. and if we print this in node then it prints an Empty Object and it is not equal to the global object of browsers bcoz there window which is a global object and 
         this we pointing to the same object.
    10. Even if we write window(came when browsers created), this(started to pointing window object in the browsers), self(concept of web workers started self), frames all
          these differnet keywords refer to the same object.  as when node js came in they use the word global and there was a decripisensy as we using js so there has to
           be a common object.
    11. So then open js foundation, decided to make a standard global object in all the runtime environment and globalThis came which refer to all the js runtime environment
         (in all browsers).


================================== Class 4 =====================================


    1. In Node JS application, there is one entry point in the application.
    2. In real life projects, we have multiple files and we want them to execute like here we got app.js which is the entry point of application and another file xyz.js in 
         which there is js code that we want to execute and both the files are not related as they are sepearted files.
    3. xyz is a sepearte module.
    4. Two modules can work together by the require function and it will first print the file which is imported through require function and then the rest of the code.
    5. By default, Modules protects their variables and functions from leaking.
    6. So if we want to use variables or functions of one module to another we have to Explicitly export them.
    7. Whatever we will export through module.exports will be return from require function.
    8. The new file we create is known as a module, and if we run require, we can access the code of different modules. However, we can't access the variables and functions
        directly because modules don't leak them. If we want to use them, we have to export them, and require will return the variable, function, or object that we export.
    9. If we export one variable or function we can write: 
         
         - for exports (best practice to wrap everything in {} whether exporting one or multiple varible or function)
         module.exports = calculateSum; or module.exports = { calculateSum };   
         
         - for imports directly put the name of that varibale or function while importing it.
         const calculateSum =  require("./sum.js");


     10. If we export more than one variable or function we can write: 
         module.exports = {
          x: x,
          calculateSum: calculateSum};  or  module.exports = { x, calculateSum }; (best practice short hand in js)

     11. Other Modules have their own private space is a super power bcoz it protects the variable, as we can use same variable name in different modules unless we importing 
            them there like x in sum.js can do whatever they want to done but as app.js don't need to done anything with x we won't import it and can use the same varibale 
            x also.

     12. Two types of modules (IMPORT/EXPORT) :
     
          - Common JS Modules (CJS)
               - module.exports and require() 
               - by default used in Node JS
               - older way   
               - Synchronous     
               - non strict mode (can declare a variable without using var, let and const)
          
          - ES Modules (MJS / ESM / ES6 Modules)
               - import and export statements
               - by default used in React, Angular
               - newer way (better/standard way of export and import modules)
               - Asynchronous
               - strict mode (compulsory to declare a variable with var, let and const)

     13. Grouping together the same kind of files/ modules and making a single module (index.js) which helps in import and export of modules (FOLDER STRUCTURE).


================================== Class 5 =====================================

     1. Inside Node JS, there is V8 engine and Node JS gives our code to V8 JS engine and it executes our code.
     2. The whole module is wrapped inside a function and then executed and thats the reason why module keep variables and functions private and only way to access them
           outside by module.exports.
     3. Whenever we create a new module and call require function for the file then Node JS takes the code from the file, wraps it into a function and then execute it and 
         if there are any variables and functions which are there inside this function, we cannot directly access it outside as we can only access if module.exports 
         exported it outside.           
     4. When we call require("./path"), All the code of the nodule is wrapped inside a function, which is a special function which is known as IIFE.    
     5. IIFE - setImmediately Invoked Function Expression

          (function () {
               
               All code of the module runs inside here

          })()
     6. When we call require(), Node JS will take all the code and wrap inside an IIFE function and then it will give it to V8 JS engine.     
     7. Why need IIFE?
           - Immediately envokes the code
           - Privacy as it keeps variable and function safe/private
           - It won't interfare the code as it is independent now

           (function () {
               var a = 1000;
           })();t

           var a = 10;
     8. How are variable and function private in different module?
           - bcoz of IIFE and require(statement) as require statement is wrapping the code inside IIFE.

     9. How do you get access to module.exports?
           - When our code is wrapped inside a function, the function has parameters module and require given by Node JS.
           - Node JS passes module as a parameter to the IIFE in which the code is wrapped.
     10. Like there is a module xyz.js now Node JS will create a IIFE and our code will be passed inside IIFE and also Node JS pass module and require as prarameter and then
            it passed to V8 engine and V8 engine executes it and all the variables and function inside the module will not interfere with rest of the other code.

     11. 5 Step Mechanism of require("./PATH")
           - Resolving the Module
                  - It checks whether the module is a local path("./xyz.js") or JSON("./data.json") path or node internal module("node:util").
                  - It checks what type of data is coming whether it is coming from node module, json file or local path and accordingly it resolves the module.
           - Loading the module
                  - File content is loaded according to file type as it can be local, json or node module.
           - Wraps inside an IIFE (Compile)
           - Code Evaluation
                  - In this step, module.exports returns means when we require, it returns the exported variables or functions Whatever we exported. 
                  - Example:-  const {calculateMultiply, calculateSum } = require("./calculate");   
           - Caching (V.V.IMP)
                  - Then the module is cached.
                  - Multiple files requiring multiple modules
                  - xyz.js module require in different modules like multiple.js, sum.js and app.js now, Node caches the require, means the code of the require will only run once.
                  - As, it will not follow all 4 steps after executing once bcoz it is already cached and it will return from the cache.
     12. Libuv library most amazing super power node js has. Eventloop is inside libuv, multi-threading happens with libuv.




================================== Class 6 =====================================

     1. Node JS has an event-driven architecture capable of Asynchronous I/O.
     2. JS is a Synchronous single threaded language.



********************************** SEASON - 02 *************************************

================================== Class 01  =====================================

     1. Waterfall Model (SDLC)
           - REQUIREMENTS                                  
           => by PM - Product/Project Manager - What is Dev Tinder? What features, adueince, differnet scenario, how, tech stack. - PM with Designers
                
                - DESIGN                                   
                => Scenior Engineers/ EM - deciding the tech stack -  Monolith or MicroService architecture - System Design - High Level Design (HLD) - Low Level Design (LLD)
                     
                     - DEVELOPMENT                         
                     => SDE1 / SDE2 - writing Unit Test Cases
                          
                          - TESTING                        
                          =>  SDET - Software Development Engineer Testing - Automation, Manual Testing 
                               
                               - DEPLOYMENT                
                               => Devops Engineer - manages server, deploy - sometimes testers - mainly developers do deployment 
                                    
                                    - MAINTAINANCE         
                                    => Repeat Cycle - some new features or changes
     2. Monolith vs MicroServices
           - Monolith
                - One Big single project which does everything.
                - It has Backend, DB connection, Frontend, code to Authenticate, code to send Emails, code to analytics, Notification.
                - All code written in a single code repository or in a single project deployed on a single way.
           - MicroServices
                - There are multiple small services (Service/project/application ).
                - There can be a micro services only for Frontend or Backend or Authentication or Notification or Analytics or Admin or Creating Dashboard.
                - In large company, there are small small projects handled by different teams and communicating with each other.
                - For example: In uber, when we book a ride there are so many micro services which get active like a micro service which just calculate the fare, other micro
                  service just for Fraud Detection, other team handling just Notifications and other team handling just Invoices/Billings.                                                       
     3. Monolith vs MicroServices Comparison
          -----------------------------
           i. Dev Speed and Code Repo 
           -----------------------------
           In Monolith, there is a single code repository where all the developers are working like 20-30 developers. As, Single Code Repo so Dev Speed is slow bcoz lot of
           developers working on the same code repository, code reviews become slower, it becomes tough for execution also, developmemt Speed becomes slow as when we want 
           to run the application we have to compile the whole project. So, Dev speed comprised a little in Monolith.

           In MicroServices, some developers are working on one service, some other developers on another service. Multiple code repo are there. We can built parallel also as
           in Monolith we can do same but in MicroServices it becomes very easier as frontend team managing their own project and Backend team managing their own backend and 
           they are building things parallely.

           -----------------------------                      
           ii. Scalability 
           ----------------------------- 
           In Monolith, in small company or Small project, Scalability is not a challenge in Monolith but as soon as big company or big project then it becomes very tough to 
           scale Monolith architecture bcoz code repositories growing day by day and maintaing that is a mess.

           In MicroServices, there are small small micro services and its easy to manage and scale those services independently.Like having analytics engine and want to scale
           it we can do it independently. Or having frontend micro service or backend micro service so solving the challenges in that small project and scaling it is easier.  

           -----------------------------
           iii. Deployment 
           -----------------------------

           In Monolith, just need to do a single deployment and whole application is deployed. One small change only in Frontend but need to deploy the whole code on to the 
           server and it is time consuming as it takes lot of process and need to go through testing and it becomes tough in Monolith. 

           In MicroServices, need to deploy each and every application seperately. So if any change in Frontend, we can just directly deploy our frontend application and all 
           other micro services work in the same way. But there can be a mismatch in frontend and backend also if they talking to differnet versions.

           -----------------------------
           iv. Tech Stack 
           -----------------------------

           In Monolith, we are restricted with the tech stack coz of one code base, like there is only one tech stack that decided initially like for frontend if it was made
           in React the whole frontend will be in React only. But if backend is in Java stack, then it will be in Java for all services like sending emails, analytics 
           Dashboard, etc.

           In MicroServices, we can built admin Dashboard with React and student Dashboard on Next js. Analytics can be built on GO, backend in Java for sending emails, but 
           backend can be on Node also for a different micro service like Notification. 

           -----------------------------
           v. Infra Cost 
           -----------------------------

           In Monolith, infra is lower as single project is deployed on a server.

           In MicroServices, it is higher as more the services more the infra required. Multiple servers for frontend and backend. seperate micro services need a seperate 
           server. 

           -----------------------------
           vi. Complexity
           -----------------------------

           In Monolith, if Project is large then Complexity is hard to maintain bcoz of single code base, files etc.

           In MicroServices, if Project is small then Complexity is tough bcoz for small project also we managing multiple services for it but if project is large then
           Complexity is easy.

           -----------------------------
           vii. Fault Isolation
           -----------------------------

           In Monolith, if one line of code is faulty or some piece of code breaks in backend then whole project breaks/crashes.

           In MicroServices, it just crashes only that micro service not the whole project. Like issue in analytics then analytics service will go down not whole project. 

           -----------------------------
           viii. Testing
           -----------------------------

           In Monolith, writing end to end test cases will be easier.

           In MicroServices, we can test the services independently and all the services will have their own test cases but writing end to end test cases is tough.

           -----------------------------
           ix. OwnerShip
           -----------------------------

           In Monolith, there is a central ownership and few people decides how deployment and work will be done.

           In MicroServices, differnt teams take the ownership of different MicroServices.

           -----------------------------
           x. Maintainance and Rewamps
           -----------------------------

           In Monolith, it is tough to do that.

           In MicroServices, its easy to maintain like if want to change whole frontend its easier to do that in MicroServices.

           -----------------------------
           xi. Debugging
           -----------------------------

           It can be tough in both bcoz if something breaks then we have to check the fault.

           In  Monolith, its slightly easier bcoz there is one code base and easy to debugg which file or code etc. 

           In MicroServices, there is blame game also as one mico service team blames other. 
           
           -----------------------------
           xiii. Dev Expierence
           -----------------------------

           MicroServices, as i can break my services to smaller services so they cna be independently updated, scale and deployment cycle.


************ my notes refined By ChatGpt ****************


1. Waterfall Model (SDLC)
     - Requirements
          - Managed by the Product/Project Manager (PM), who defines the product scope, target audience, features, and scenarios. PMs often collaborate with designers to 
          refine the tech stack and outline project goals.
     
     - Design
          - Led by Senior Engineers or Engineering Managers (EM), who decide on the tech stack, architecture type (Monolith or Microservices), and perform System Design.
          Design phases include High-Level Design (HLD) and Low-Level Design (LLD) to clarify the architecture.

     - Development
          - Primarily handled by SDE1 / SDE2 (Software Development Engineers) who write unit test cases and develop the core codebase.

     - Testing
          - Performed by Software Development Engineers in Test (SDET), responsible for automation and manual testing to ensure software quality.

     - Deployment
          - Managed by DevOps Engineers who handle server management, deployment, and infrastructure. Deployment may involve testers but is often primarily done by developers.

     - Maintenance
          - This is an ongoing cycle where new features or updates are introduced, requiring repeated steps from requirement gathering to deployment.

2. Monolith vs. Microservices

     - Monolith
          - A single, unified project containing everything (backend, frontend, database connections, authentication, emails, notifications, analytics) within a single code 
     repository.
          - All code is deployed together, which simplifies deployment but can limit flexibility.
     
     - Microservices
          - A collection of smaller, independent services (e.g., Frontend, Backend, Authentication, Notifications, Analytics).
          - Each microservice operates as a separate project with independent teams, making scaling easier in large organizations.

3. Monolith vs. Microservices: Comparison
     
     - i. Development Speed and Code Repository
          - Monolith: Single code repo for all developers, which can slow down development due to merge conflicts and longer build times.
          - Microservices: Multiple code repos allow teams to work independently, speeding up development as frontend and backend teams can build and deploy in parallel.
     
     - ii. Scalability
          - Monolith: Suits small companies/projects but becomes hard to scale as the project grows.
          - Microservices: Allows independent scaling of services, making it ideal for large projects needing flexible resource management.
     
     iii. Deployment
          - Monolith: Single deployment, but even minor changes require redeploying the entire application.
          - Microservices: Independent deployments mean changes in one service (e.g., frontend) don’t impact others, although version mismatches can cause issues.
     
     iv. Tech Stack Flexibility
          - Monolith: Limited to a single tech stack across the application (e.g., React for frontend, Java for backend).
          - Microservices: Allows diverse tech stacks across services, such as React for one dashboard, Next.js for another, and separate backend languages for different microservices.
     
     v. Infrastructure Cost
          - Monolith: Lower infra costs as only one server is typically needed.
          - Microservices: Higher costs due to separate servers for each service.
     
     vi. Complexity
          - Monolith: Complexity rises in large projects due to a single, monolithic codebase.
          - Microservices: Easier for large projects but overkill for small projects, where managing multiple services adds unnecessary complexity.
     
     vii. Fault Isolation
          - Monolith: Failure in one area can impact the entire application.
          - Microservices: Issues are isolated to the specific service, minimizing overall impact.
     
     viii. Testing
          - Monolith: Easier to write end-to-end tests as there’s a single codebase.
          - Microservices: Independent tests for each service simplify testing but make full integration testing more complex.
     
     ix. Ownership
          - Monolith: Centralized ownership, with few decision-makers overseeing the project.
          - Microservices: Different teams own different services, allowing for distributed responsibility.
     x. Maintenance and Revisions
          - Monolith: Harder to manage large-scale updates and rewrites.
          - Microservices: Easier to modify specific parts, like a frontend revamp, without impacting other services.
     xi. Debugging
          - Monolith: Easier, as there’s one codebase to check for issues.
          - Microservices: Complex, with potential inter-team “blame game” as faults can cross service boundaries.
     xii. Developer Experience
          - Microservices: Greater flexibility, as services can be broken into smaller parts, making it easier to update, scale, and deploy independently.

================================== Class 02  =====================================

     1. Features in DevTinder
           i. Create an account
           ii. Login
           iii. Update your profile
           iv. Feed page - explorer
           v. Send connection request
           vi. See our matches
           vii. See the request we've sent/received
           viii. Update your profile
     2. Product requirements given by PM. PM collabarats with Design team to Design the UI mock.
     3. HIGH LEVEL DESIGN (HLD)
           A. Tech Lead/Engineering Manager will read these requirements and will figure out HLD of the product like what micro services will be built, security practices 
           use(JWT token), how to store the password, how to encrypted and decrypted, how to check for validation, how will user Authenticate, how will be the database be,
           what database will be used, how we will Design the database, how we will Design the api etc.
           B. Tech Planning
               - 2 MiccroServices 
                   - Frontend(React) and Backend (Node js and MongoDB)
     5. LOW LEVEL DESIGN (LLD)
           A. In DB design, we decides collection of documents like what kind of collection will be there.
               - Collection
                    i. User => firstname, lastname, email id, password, age, gender etc
                         - We also discuss in the DB design that if it is a first name it should be a string, with min and max length.
                         - We discuss and decide the datatype of the fields in the document like age should be a number.
                         - How will uh store the password or what should be the values in gender.
                         - When we have such type of model where one user can send connection requeet to lot of other user then we have to store that relationship information
                          also means need one more collection.
                          - Will not store in user collection bcoz it is used to store user data not the data of their connections/relationships.
                    ii. ConnectionRequest => From user id, To user id, status (pending/accepted/rejected).
                         - Now if we think, here we decided that there can be 3 status that A can send request to B and it can be in pending status then either it will be
                          accepted or rejected but there can be more than 3 status as well. Like pending status when A will be right swipe but what if A will left swipe it,
                           that can be a 4 status named as Ignored, even there can be a one more status i.e. 5 status named Blocked if A blocks.
           B. In API Design, there are HTTP method that we use for RESTful API i.e. GET, POST, PUT, PATCH and DELETE.
               - In some comapnaies they create api's like /getProfile, /updadeProfile etc. but in companies where they follow good nomenclature they use it like Get/profile 
               to get the data of the profile, Post/profile to send the data to the profile.
               - In DevTinder, we making CRUD Operations like 
                 - Post/signup
                 - Post/login
                 - Get/profile
                 - Post/profile
                 - Patch/profile
                 - Delete/profile
                 - Post/sendRequest => Ignore or Interested
                 - Post/reviewRequest => Accept or Reject
                 - Get/requests 
                 - Get/connections

************** HOME WORK **************

1. WHAT IS REST API?

A REST API (Representational State Transfer Application Programming Interface) is a set of rules and conventions that allows software applications to communicate
with each other over the web. REST is an architectural style used primarily for building web services, and it defines how resources, such as data or functions, can be 
requested or modified by other applications.

Here's an overview of how REST APIs work:

1. Resources and Endpoints
In REST, everything is considered a resource. A resource could be anything you want to expose via the API, like a user, product, or article. Each resource is identified by a
URL (Uniform Resource Locator), called an endpoint.
For example, an API endpoint like /users could be used to interact with user data.

2. HTTP Methods
REST APIs commonly use HTTP methods to define the type of action requested on a resource. The primary methods are:
GET: Retrieve data (e.g., get a user’s information)
POST: Create new data (e.g., add a new user)
PUT or PATCH: Update existing data (e.g., modify user information)
DELETE: Remove data (e.g., delete a user)
These methods help keep the API simple and intuitive by using standard web protocol actions.

3. Statelessness
REST APIs are stateless, meaning that each request from a client to the server must contain all the necessary information for the server to fulfill the request. No client 
context is stored on the server between requests, which simplifies server design and allows it to scale more easily.

4. Data Formats (Usually JSON)
REST APIs commonly use JSON (JavaScript Object Notation) to send and receive data because it’s lightweight and easily readable by humans and machines. However, other formats 
like XML can also be used.
When a client requests data, the server responds with the resource in JSON format, making it easy to integrate with frontend applications.

5. Standard HTTP Responses
REST APIs use standard HTTP status codes to indicate the result of a request:
200 OK: Successful request
201 Created: Successful creation of a resource
400 Bad Request: Incorrect request format
401 Unauthorized: Authentication required
404 Not Found: Resource not found
500 Internal Server Error: A general server error

Example
Imagine a REST API for a library system where you want to manage book records:

GET /books – Retrieves a list of all books.
GET /books/1 – Retrieves information about a specific book with ID 1.
POST /books – Adds a new book to the library.
PUT /books/1 – Updates the information for the book with ID 1.
DELETE /books/1 – Deletes the book with ID 1.
Each endpoint and method works consistently, allowing different applications to communicate seamlessly with the library system.

In essence, a REST API is a way of building APIs that are intuitive, reliable, and easy to interact with, especially suited for web-based applications and services.


2. Differnce between put and patch api?

The difference between PUT and PATCH in REST APIs lies in the way they update resources:

i. PUT:

Full Update: The PUT method replaces the entire resource with the data provided in the request. If fields are omitted in the request, they may be set to default or empty 
values.

Idempotent: Multiple identical PUT requests have the same effect as a single request.

Example: If you have a user resource with fields like name, email, and age, and you send a PUT request to update just name, you must still include email and age in the 
request; otherwise, those fields might be reset.

PUT /users/1
{
    "name": "John Doe",
    "email": "johndoe@example.com",
    "age": 25
}

ii. PATCH:

Partial Update: The PATCH method applies a partial update to a resource, modifying only the fields specified in the request without affecting other fields.

Idempotent: Like PUT, PATCH is also idempotent; sending the same PATCH request multiple times produces the same result.

Example: With PATCH, you can send only the name field if that's the only thing you want to update, leaving other fields like email and age unchanged.

PATCH /users/1
{
    "name": "John Doe"
}

Feature	      |   PUT	                            |     PATCH
Update Type	 |   Full (replaces entire resource)  |     Partial (updates specified fields)
Idempotent	 |   Yes	                            |     Yes
Usage Scenario	 |   Replace an entire resource	   |     Update a specific field(s) of a resource

In short: Use PUT when you want to replace an entire resource and PATCH when you want to modify specific fields.


================================== Class 03  =====================================

    1. For Creating a project, create a folder, open it in vs code and in terminal do npm init to initliase it and package.json file will be created then create src folder
    and inside that app.js file. Now, npm i express to install express in the project and then node modules folder and package-lock.json file will be created.
    2. Node modules folder contains all the code of install packages like here we installed express so it took all the code of express and put it in node modules folder.
    3. Also, in package.json npm added express as the dependency of our project.
    4. Other folders than express are there in nod modules bcoz express also have package.json file and some dependencies so it installed them also and if those dependencies
    of express have some dependencies then it will also be installed in node modules.
    5. As, we have express version as ^4.21.1 which is equals to (major.minor.patch) so as express js is a library and it is constantly updated as lot of devlopers working 
    on it. As we using express as 4.21.1 so now will see how it updates.
         - patch => It is for small change or small bug fix and push it. version will be 4.21.2
         - minor => It is for minor change like pushing some features inside express and those features are backward compatible means any older version users won't face any 
         issues due to minor change in version. version will be 4.22.2
         - major => It is for major change like express changing something internally which will effect any people who using 4.x.x as it is breaking change and it is not 
         backward compatible as updated version will be 5.20.3   
     6. When we use carat ^ like ^4.21.1 it means our project will automatically be updated if any of the new version comes in 4.x.x series means if there is any patch or 
     minor change then it automatically update our project.
     7. If we don't use carat or tilde then it means it will be on the version in which it was initially created. Like 4.21.1
     8.Using ~4.21.1 means that your project can automatically update to any new patch version within the specified minor version. This means it will only allow updates that
     are bug fixes and do not introduce new features. Like, it would allow updates to 4.21.2, 4.21.3, etc., but it would not allow updates to 4.22.0 or any higher major 
     version like 5.0.0.
     9. package-lock.json will tell the exact version of the package and in package.json it tells the version that we allowed not the exact version.



************** HOME WORK **************

    1. What are Dependencies?
    Dependencies are external libraries or modules that a project needs to function. When a project relies on certain packages, we declare them as dependencies so that 
    they’re automatically installed and included when setting up the project. In Node.js projects, dependencies are listed in the `package.json` file under `"dependencies"`
    or `"devDependencies"` sections.
    
    - Dependencies: Listed in the `"dependencies"` section, these are packages required for the project to run in production.
    - DevDependencies: Listed in the `"devDependencies"` section, these are only needed during development, such as testing frameworks or build tools, and not necessary
    in production.

    2. What is the Use of `-g` in `npm install`?
    The `-g` (global) flag in `npm install -g <package-name>` installs the package globally, meaning it’s available system-wide rather than just in the current project 
    directory. 

    - Global Installation (`-g`): The package can be used anywhere on the system, typically for command-line tools like `nodemon` or `create-react-app`.
    - Local Installation (without `-g`): The package is installed only for the specific project and will be found in the project’s `node_modules` folder.

    3. Difference Between Caret (`^`) and Tilde (`~`)
    The caret (`^`) and tilde (`~`) symbols are version specifiers for dependencies in the `package.json` file. They define the range of versions that 
    npm will install, controlling which updates are allowed.

    - Caret (`^`):
       - Allows updates to the **minor** and **patch** versions, but locks the major version.
       - Example: `^4.2.1` allows updates to `4.3.0`, `4.9.5`, etc., but not `5.0.0`.
       - It is commonly used to provide some flexibility for newer features and bug fixes while avoiding potential breaking changes.

    - Tilde (`~`):
       - Allows updates only to the **patch** version, locking both the major and minor versions.
       - Example: `~4.2.1` allows updates to `4.2.2`, `4.2.5`, etc., but not `4.3.0`.
       - Useful when you want the smallest range of updates, generally just bug fixes.
       
       In summary:
       - `^` (caret)**: More flexible; allows updates within the same major version.
       - `~` (tilde)**: More restrictive; allows updates within the same minor version only.



================================== Class 04  =====================================

    1. We can delete node modules as whenever we do npm i it will install the node module again as per the dependencies in package.json. Hence, we don't push node mpdules to
    the git.
    2. To ignore certain folders or files, like node modules we can create a file called gitignore and inside that we can give path/name of the files that we want it to 
    ignore.
    3. Also, whenever we use routes like we did /hello then it matches the exact path /hello so even if we do /hello/1 or /hello/test it will show the same output of hello
    only unless we specifically define routes for /hello/1 or /hello/test and thats why when we used / it showed same output even after changing the link to /hello or /test.
    4. In other words, /hello will match additional segments (like /hello/1) unless we restrict it, so that’s why /hello, /hello/test, and /hello/1 might return the same 
    response unless specifically defined otherwise.
    5. / is the root route, handling requests to the very base URL. /hello is a specific route, and /hello/anything would still match /hello if the router is set to allow
    path matching with additional segments.
    6. The order of writing routes in the code is very very important. 
    7. As, now if we shift / route at last after /hello and /test then all three works fine. Same if we
    created a route /hello/2 and if it is after /hello then it will show same output in both /hello and /hello/2 but if it is befoer /hello then both will show their 
    resprective output.    
    8. in Postman, just made a new workspace for new project and inside that we can create new collection (collection here is just collection of api) while click on new we
     can choose methods like http and then test API calls.
    9. When we use app.use("/hello), then if we do GET or POST request in postman to test api it will show the same output for both as it matches all the HTTP method to api
    call. 
    10. Use http methods with app seperately like app.get("/user") so now this method will only match the get api calls to the route "/user" as it will only handle GET call to
    "/user" means it will only show the data of get method or if we do app.post("/user") so it will only handle POST call to "/user".
    11. If we using HTTP methods with app seperately like app.get("/user") or app.post("/user") but above all of them if we use app.use("/user") then it will again show same
     result/output for all the methods bcoz all the routes will handled over "/user" whether it is a GET or a POST method bcoz order matters as dicsused earlier.
    12. Advance Routing
          i. if we put ? after a letter then that letter above ? will be optional.
               - app.get("/ab?c")
               - here it will be work for /abc and /ac also as b is optional.
          ii. if we put + after a letter then that letter above ? can be used multiple times.
               - app.get("/ab+c")
               - here it will be work for /abc and /abbc or /abbbbbbbbbbbbbbbbbbbc.
               - but won't work for /abbbbbbbcc as pattern needs to be follow i.e. a and c has to be in last and we can add as many as b we want to add.
          iii. if we put * between two letters then we can add anything in between those two letters.
               - app.get("/ab*cd")
               - here it will be work for /abcd and /abAnythingYouCanADDcd. 
          iv. a. if we group things together like keeping two letters in a bracket () and then using ? then those letters above ? in bracket will be optional.
               - app.get("/a(bc)?d")
               - here it will be work for /abcd and /ad as bc become optional.
              b. if we group things together like keeping two letters in a bracket () and then using + then those letters above + in bracket can be used multiple times.
               - app.get("/a(bc)+d")
               - here it will be work for /abcd and /abcbcbcbcbcd as bc become optional.
          v. we can also use regex instead of a string like /a/
               - app.get(/a/, (req, res) => {})
               - if a comes anywhere it will work like /a or /cab or /can
               - it won't work for /b or /cid
          vi. if we use /.*fly$/ then anything can be in starting and it ends with a fly it will work.
               - app.get(/.*fly$/, (req, res) => {})
               - here it will work for /butterfly or /fly or /dragonfly or /seeWhatUhSeefly.
               - it won't work for /dragonfly1 or /butterflyInSky
     13. How to get Query parameters/params in route handler like /user?userId=101 or /user?userId=101&password=testing
          - We can get it by req.query 
          - output will be {userId: '101', password: 'testing'}
     14. How to make routes dynamic or dynamic api's like  /user/100 or /user/100/Saurav/testing
          - colon : means dynamic routes just add : after / like /user/:userId or  /user/:userId/:name/:password
          - We can get it by req.params
          - output will be {userId: '101'}        
                


************** HOME WORK **************



    1. Difference Between package.json and package-lock.json?
         - package.json
              - This file contains a general list of the project’s dependencies along with their versions (often using version ranges).
              - It specifies information like project name, version, author, scripts, and dependencies (dependencies and devDependencies).
              - The versions listed in package.json allow some flexibility. For example, "express": "^4.17.1" means that npm can install any compatible version like 4.17.2 
              or 4.18.0.
          
         - package-lock.json
              - This file locks the specific versions of all installed dependencies, including sub-dependencies (dependencies of dependencies).
              - It captures the exact version numbers that were installed during the last npm install command, providing a detailed "snapshot" of the dependency tree.
              - Ensures that the project will install the same dependency versions each time, providing consistency across different environments (development, staging, 
              production).
     2. Should You Push package-lock.json to GitHub?
          - Yes, you should push package-lock.json to GitHub.
          Here’s why:
          - Consistency: package-lock.json ensures that all collaborators and environments use the exact same versions of dependencies. Without it, npm install could install 
          slightly different versions due to the version ranges in package.json, potentially causing bugs and inconsistencies.
          - Faster Installations: When package-lock.json is present, npm can skip steps in dependency resolution, making installations faster and more efficient.
          - Security: Since it locks dependencies to specific versions, package-lock.json can help prevent unintentional updates that might introduce vulnerabilities.
          
          In short, package-lock.json is essential for reliable, consistent dependency management, which is why it should be included in version control.

     3. differnce between query and params?
          - In web development, both query and params (also called route parameters) are used to send data in URLs, but they are used in different ways and have different 
          formats:

          I. Query Parameters
               - Format: Key-value pairs appended to the URL after a question mark (?).
               - Example URL: https://example.com/search?category=books&sort=asc
               - Access in Express.js: Using req.query.
               - Use Case: Query parameters are generally used for optional data or filters. They allow passing multiple values without changing the URL structure and are often used
                for searches, filters, pagination, sorting, etc.

               // Example in Express.js
               app.get('/search', (req, res) => {
                    const category = req.query.category;  // 'books'
                    const sort = req.query.sort;          // 'asc'
                    res.send(`Category: ${category}, Sort: ${sort}`);
                    });

          II. Route Parameters (Path Parameters)
               - Format: Part of the URL path itself, defined with a : followed by the parameter name in the route.
               - Example URL: https://example.com/products/12345
               - Access in Express.js: Using req.params.
               - Use Case: Route parameters are used for required values that identify specific resources or entities, like an item ID, user ID, or product category. 
               They make the URL cleaner and more readable when pointing to specific items or resources.

               // Example in Express.js
               app.get('/products/:id', (req, res) => {
                    const productId = req.params.id;  // '12345'
                    res.send(`Product ID: ${productId}`);
                    });

          Key Differences
               - URL Structure: Query parameters are added at the end of the URL with ?, while route parameters are part of the URL path itself.
               - Use: Query parameters are usually optional and used for filtering or sorting data. Route parameters are typically required and represent specific entities or
                resources.
               - Data Access: Query parameters are accessed with req.query and route parameters with req.params in Express.js.          



================================== Class 04  =====================================































************** Cloning a repo **************

          For git repo, if i made the repo first then either i can come to pc and create folder inside that open cmd and git clone link of repo and clone it and open that 
          folder in vs code or i can directly come to vs code and click on clone the repository and it will then ask me the folder where i want to clone it and i can choose 
          that folder and clone it.
          but if i started the code and haven't created the repository then i can do git init to iniitalise it then git add . then git commit -m "commit files" and now push 
          it to the github so will go on github and create a new repo and map it to the repository by adding 3 commands which wil be mentioned there only when we create the 
          repository.
          git remote add origin
          git branch -M main
          git push -u origin main